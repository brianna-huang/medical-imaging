{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## CNN: Classifying X-ray images\n",
        "\n",
        "In the notebook below, we will be building convolutional neural networks to classify X-ray images of lungs in the hopes of identifying those lungs that show signs of pneumonia. We will ultimately classify the lungs as either \"Normal\" or \"Pnuemonia.\" Numerically, these classes will be represented as 0 (for Normal) and 1 (for Pneumonia), respectively."
      ],
      "metadata": {
        "id": "3txwXBPcVbNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** You can greatly improve the computation speed in Google Colab by connecting to a GPU. Click the \"Runtime\" tab in the top ribbon, then \"Change runtime type\". You can then select \"T4 GPU\". Note, however, that GPUs are subject to availability; Google has a fixed (and unspecified) amount of resources available at any given time, so a GPU may not be available. Feel free to try again later if you don't succeed at first."
      ],
      "metadata": {
        "id": "FsUHOzE-q3ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries to Import"
      ],
      "metadata": {
        "id": "Ih5rxQ8aB5Vm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyPnwAX-UXbL",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685133af-0dd1-4c4c-896c-4a72b7330f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.18.0 in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.18.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.18.0) (0.1.2)\n",
            "Requirement already satisfied: keras==3.8.0 in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras==3.8.0) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras==3.8.0) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras==3.8.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras==3.8.0) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras==3.8.0) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras==3.8.0) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras==3.8.0) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras==3.8.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras==3.8.0) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras==3.8.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras==3.8.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.8.0) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.18.0\n",
        "!pip install keras==3.8.0\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Real quick**: make sure tensorflow and keras are version 2.18.0 and 3.8.0, respectively by running the cells below.\n",
        "\n",
        "If either is showing the wrong version, restart the session by clicking the \"Runtime\" tab up top and selecting \"Restart session\". After that, run the notebook again from the top."
      ],
      "metadata": {
        "id": "0Tuguwo2cOHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show tensorflow #Should be version 2.18.0"
      ],
      "metadata": {
        "id": "yaaYnh-6cMJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1041bdcc-b922-4040-9636-e11ce3632685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.18.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine_rl, tensorflow-text, tensorflow_decision_forests, tf_keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show keras #Should be version 3.8.0"
      ],
      "metadata": {
        "id": "89_1NMfTdA3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98d5424-6e02-4cf2-ef21-cf5694d46433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: keras\n",
            "Version: 3.8.0\n",
            "Summary: Multi-backend Keras\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Keras team <keras-users@googlegroups.com>\n",
            "License: Apache License 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: absl-py, h5py, ml-dtypes, namex, numpy, optree, packaging, rich\n",
            "Required-by: tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_random_seed():\n",
        "  seed = 118\n",
        "  # Set random seeds for reproducibility\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  tf.random.set_seed(seed)\n",
        "\n",
        "  # (For TensorFlow GPU determinism)\n",
        "  os.environ['CUDA_VISBLE_DEVICE'] = ''\n",
        "  os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "  os.environ['PYTHONHASHSEED'] = str(1234)"
      ],
      "metadata": {
        "id": "-g5mu_gedGPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Loading the Image Data"
      ],
      "metadata": {
        "id": "Y7t7eedrCVty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this cell, but DO NOT EDIT\n",
        "def get_data(pkl_path):\n",
        "    with open(pkl_path, 'rb') as f:\n",
        "      # Read the data from the file\n",
        "      data = pickle.load(f)\n",
        "    return data"
      ],
      "metadata": {
        "id": "NlvKdtcWl3to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this cell, but DO NOT EDIT\n",
        "\n",
        "train = get_data(\"chest_xray_train.pkl\")\n",
        "test = get_data(\"chest_xray_test.pkl\")\n",
        "val = get_data(\"chest_xray_val.pkl\")"
      ],
      "metadata": {
        "id": "4jj_LPmommy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just for fun, run the code below to see a sample image. Note that `train[i][0] `returns the i-th training image array and `train[i][1]` returns the label (0 for Normal or 1 for Pneumonia) corresponding to the i-th training image:"
      ],
      "metadata": {
        "id": "6J1zcwdVrme4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Label = {train[0][1]}\")\n",
        "train[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "kYepR5C-nw2Q",
        "outputId": "49dc2601-2fad-4b60-a5c0-34f709c44813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label = 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[38, 34, 36, ..., 67, 56, 55],\n",
              "       [41, 43, 43, ..., 61, 56, 54],\n",
              "       [43, 46, 44, ..., 55, 56, 55],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-352a2a5e-5e3f-4160-85da-a71f82f72ace\" class=\"ndarray_repr\"><pre>ndarray (150, 150) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[38, 34, 36, ..., 67, 56, 55],\n",
              "       [41, 43, 43, ..., 61, 56, 54],\n",
              "       [43, 46, 44, ..., 55, 56, 55],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-352a2a5e-5e3f-4160-85da-a71f82f72ace button').onclick = (e) => {\n",
              "        document.querySelector('#id-352a2a5e-5e3f-4160-85da-a71f82f72ace').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-352a2a5e-5e3f-4160-85da-a71f82f72ace button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Data Preparation"
      ],
      "metadata": {
        "id": "dg8EFIEYyGaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As noted above, the image data and labels are both part of the same master array (the train, test, or val arrays). In order to prepare things for neural networks, we need to split up the images from their labels. We will call the image arrays our x values and their respective labels our y values.\n",
        "\n",
        "`train[i][0]` returns the i-th training image array and `train[i][1]` returns the label (0 for Normal or 1 for Pneumonia) corresponding to the i-th training image.\n",
        "\n"
      ],
      "metadata": {
        "id": "l_dj5BqnykOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = [train[i][0] for i in range(len(train))]\n",
        "y_train = [train[i][1] for i in range(len(train))]\n",
        "\n",
        "x_val = [val[i][0] for i in range(len(val))]\n",
        "y_val = [val[i][1] for i in range(len(val))]\n",
        "\n",
        "x_test = [test[i][0] for i in range(len(test))]\n",
        "y_test = [test[i][1] for i in range(len(test))]"
      ],
      "metadata": {
        "id": "tVP6wrMlnwg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the image arrays contain values between 0 and 255. In preperation for inputting this data into a neural network, we need to normalize these values so that they are between 0 and 1 instead."
      ],
      "metadata": {
        "id": "ClMp4XjYCr2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train) / 255\n",
        "x_val = np.array(x_val) / 255\n",
        "x_test = np.array(x_test) / 255"
      ],
      "metadata": {
        "id": "Xu7ZmRaDnwTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a final bit of data prep, we need to do two things:\n",
        "\n",
        "\n",
        "1.   Reshape `x_train`, `x_val`, and `x_test` such that they are a numpy array of shape (|x|, 150, 150, 1), where |x| is the number of images in each array. For example, if done correctly, `x_train` should be a numpy array of shape (5216, 150, 150, 1) since |`x_train`| is 5216 (i.e. there are 5216 images in `x_train`)\n",
        "2.   Convert `y_train`, `y_val`, and `y_test` to numpy arrays. We do not need to reshape these arrays because they are just one dimensional lists of zeros and ones.\n",
        "\n"
      ],
      "metadata": {
        "id": "bGauAW0_DyJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Reshape x_train, x_val, and x_test such that they are numpy arrays of shape (|x|, 150, 150, 1)\n",
        "x_train = x_train.reshape(x_train.shape[0], 150, 150, 1)\n",
        "x_val = x_val.reshape(x_val.shape[0], 150, 150, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 150, 150, 1)"
      ],
      "metadata": {
        "id": "RVO_ezg9FH3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Convert y_train, y_val, and y_test to numpy arrays.\n",
        "y_train = np.array(y_train)\n",
        "y_val = np.array(y_val)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "wJsn0jHYFd8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have our data prepped and ready to go. All of our x arrays contain normalized 150x150 images with a single channel. Note that if we were using RGB images, our x arrays would need to be of shape (|x|, 150, 150, 3), where 3 represents the red, green, and blue channels.\n",
        "\n",
        "Likewise, our y labels are in a nice one-dimensional numpy array since they are just a series of zeros and ones.\n",
        "\n",
        "We are now ready to build our convolutional neural network."
      ],
      "metadata": {
        "id": "FT5zLy8wF0--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3a: Building a Basic CNN"
      ],
      "metadata": {
        "id": "CJaAMcuAHnwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras is a powerful and user-friendly deep learning library authored by Google. It acts as a high-level API, making it easier to build and train various neural network architectures.\n",
        "\n",
        "In the cell below, you'll note that things begin with `model = keras.Sequential()`. Here, `Sequential()` creates a sequential model object that defines how layers are stacked and connected within the model."
      ],
      "metadata": {
        "id": "IBnP-XLLKV4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_random_seed()\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "7DJqhTX_JbfJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "6d92692f-d2fa-4701-8091-401bda625f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36992\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m4,735,104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36992</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,735,104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,827,905\u001b[0m (18.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,827,905</span> (18.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,827,905\u001b[0m (18.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,827,905</span> (18.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now ready to train our model.\n",
        "\n",
        "*   Before training, we specify the number of training epochs to be used and the batch size needed for training.\n",
        "*   Note that we are exclusively using `x_train` and `y_train` during training. We will save `x_test` and `y_test` for the end as a means to evaluate our model. In the meantime, we can use `x_val` and `y_val` to observe how performance improves/worsens over the epochs.\n",
        "*   Training may take a while (depending on your model, it could take about an hour). Connecting to a GPU can dramatically improve performance, however.\n",
        "\n"
      ],
      "metadata": {
        "id": "GCRiHCQpZmmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 15\n",
        "batch_size = 32\n",
        "\n",
        "model.fit(x = x_train, y = y_train, epochs= num_epochs, validation_data = (x_val, y_val), batch_size = batch_size)"
      ],
      "metadata": {
        "id": "SB2P2wJDX0cx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35f0f0a-92ad-4383-f905-5e93db9d0ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - binary_accuracy: 0.8343 - loss: 0.3711 - precision_1: 0.8456 - recall_1: 0.9522 - val_binary_accuracy: 0.8125 - val_loss: 0.2828 - val_precision_1: 1.0000 - val_recall_1: 0.6250\n",
            "Epoch 2/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - binary_accuracy: 0.9509 - loss: 0.1359 - precision_1: 0.9648 - recall_1: 0.9685 - val_binary_accuracy: 1.0000 - val_loss: 0.0913 - val_precision_1: 1.0000 - val_recall_1: 1.0000\n",
            "Epoch 3/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - binary_accuracy: 0.9738 - loss: 0.0756 - precision_1: 0.9829 - recall_1: 0.9814 - val_binary_accuracy: 1.0000 - val_loss: 0.1534 - val_precision_1: 1.0000 - val_recall_1: 1.0000\n",
            "Epoch 4/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9771 - loss: 0.0720 - precision_1: 0.9869 - recall_1: 0.9820 - val_binary_accuracy: 1.0000 - val_loss: 0.0615 - val_precision_1: 1.0000 - val_recall_1: 1.0000\n",
            "Epoch 5/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9835 - loss: 0.0450 - precision_1: 0.9919 - recall_1: 0.9856 - val_binary_accuracy: 1.0000 - val_loss: 0.0637 - val_precision_1: 1.0000 - val_recall_1: 1.0000\n",
            "Epoch 6/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - binary_accuracy: 0.9856 - loss: 0.0386 - precision_1: 0.9909 - recall_1: 0.9895 - val_binary_accuracy: 0.9375 - val_loss: 0.2094 - val_precision_1: 0.8889 - val_recall_1: 1.0000\n",
            "Epoch 7/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9872 - loss: 0.0363 - precision_1: 0.9924 - recall_1: 0.9902 - val_binary_accuracy: 0.6250 - val_loss: 0.5081 - val_precision_1: 0.5714 - val_recall_1: 1.0000\n",
            "Epoch 8/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - binary_accuracy: 0.9810 - loss: 0.0485 - precision_1: 0.9862 - recall_1: 0.9880 - val_binary_accuracy: 1.0000 - val_loss: 0.0285 - val_precision_1: 1.0000 - val_recall_1: 1.0000\n",
            "Epoch 9/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9898 - loss: 0.0252 - precision_1: 0.9929 - recall_1: 0.9933 - val_binary_accuracy: 1.0000 - val_loss: 0.0684 - val_precision_1: 1.0000 - val_recall_1: 1.0000\n",
            "Epoch 10/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - binary_accuracy: 0.9911 - loss: 0.0222 - precision_1: 0.9937 - recall_1: 0.9942 - val_binary_accuracy: 1.0000 - val_loss: 0.0117 - val_precision_1: 1.0000 - val_recall_1: 1.0000\n",
            "Epoch 11/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - binary_accuracy: 0.9934 - loss: 0.0157 - precision_1: 0.9961 - recall_1: 0.9950 - val_binary_accuracy: 0.9375 - val_loss: 0.1038 - val_precision_1: 0.8889 - val_recall_1: 1.0000\n",
            "Epoch 12/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - binary_accuracy: 0.9984 - loss: 0.0053 - precision_1: 0.9990 - recall_1: 0.9989 - val_binary_accuracy: 1.0000 - val_loss: 0.0174 - val_precision_1: 1.0000 - val_recall_1: 1.0000\n",
            "Epoch 13/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.9967 - loss: 0.0106 - precision_1: 0.9983 - recall_1: 0.9972 - val_binary_accuracy: 0.8750 - val_loss: 0.1669 - val_precision_1: 0.8000 - val_recall_1: 1.0000\n",
            "Epoch 14/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - binary_accuracy: 0.9970 - loss: 0.0091 - precision_1: 0.9981 - recall_1: 0.9979 - val_binary_accuracy: 0.9375 - val_loss: 0.0590 - val_precision_1: 0.8889 - val_recall_1: 1.0000\n",
            "Epoch 15/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9979 - loss: 0.0059 - precision_1: 0.9980 - recall_1: 0.9991 - val_binary_accuracy: 1.0000 - val_loss: 0.0110 - val_precision_1: 1.0000 - val_recall_1: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f631e073fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3b: Evaluate the Basic CNN"
      ],
      "metadata": {
        "id": "ZRjxIy8z4JhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's time to generate predictions and evaluate our model. To do so, run the cell below. You should be able to achieve accuracy scores >= 75%. If not, try a different approach, retrain your model, and return here to check the results."
      ],
      "metadata": {
        "id": "8ton1afYd8wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(x_test,y_test)\n",
        "print(f\"Accuracy: {results[1]}\")\n",
        "print(f\"Precision: {results[2]}\")\n",
        "print(f\"Sensitivity: {results[3]}\")"
      ],
      "metadata": {
        "id": "_wNpA-bxctUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c05585b8-761f-460e-9d78-da63f14a6ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.5466 - loss: 6.5869 - precision_1: 0.3612 - recall_1: 0.6651\n",
            "Accuracy: 0.7516025900840759\n",
            "Precision: 0.7179962992668152\n",
            "Sensitivity: 0.9923076629638672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save our model as follows:\n",
        "\n",
        "1.   Mount your Google Drive to this notebook by running the cell below. This will allow you to save your models within this Colab Notebook to your Google Drive.\n",
        "2.   Decide where in your Drive you would like to save your model. You will need to construct a file path to this location. For example, \"drive/MyDrive/EAS5860/\"\n",
        "3.   Populate the `path` variable in the second cell below with your desired file path and run the cell to save your model.\n",
        "\n"
      ],
      "metadata": {
        "id": "HL8EagD_EqAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this cell to mount your Google Drive (click through pop-up windows to authenticate)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97ToQ7PXKdvo",
        "outputId": "a4151761-54d4-4539-c25e-4e2b6d543a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"drive/MyDrive/\"\n",
        "\n",
        "model.save(os.path.join(path, \"EAS5860_HW4_Part_3.keras\"))"
      ],
      "metadata": {
        "id": "-t7ep_YMEpQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 4a: Dropout Layers"
      ],
      "metadata": {
        "id": "xs0twWWkxwvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may have noticed during the training of your CNN above that the model performs better on the training data than it does on the testing data. When a model performs well on training data, but fails to generalize well on unseen data, we say that the model is \"overfit\".\n",
        "\n",
        "One way to prevent overfitting is to include dropout layers within the network.\n",
        "\n",
        "1.   .   Note the effect of the Dropout Layer(s) on the model's performance. It may or may not improve the Accuracy, Precision, or Sensitivity. Experiment with different configurations.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eOL--K-gWA6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_random_seed()\n",
        "\n",
        "model_dropout = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(0.25),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_dropout.compile(optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "model_dropout.summary()"
      ],
      "metadata": {
        "id": "G0wZa3nZV__U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "c8f7c123-b036-490f-f486-5a0fe57751fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36992\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36992\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m4,735,104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36992</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36992</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,735,104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,827,905\u001b[0m (18.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,827,905</span> (18.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,827,905\u001b[0m (18.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,827,905</span> (18.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 15\n",
        "batch_size = 32\n",
        "\n",
        "model_dropout.fit(x = x_train, y = y_train, epochs= num_epochs, validation_data = (x_val, y_val), batch_size = batch_size)"
      ],
      "metadata": {
        "id": "3C6bOD-uhv_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd0808d0-2595-45d5-a9a2-bb9f21a8e6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - binary_accuracy: 0.8212 - loss: 0.4179 - precision_2: 0.8255 - recall_2: 0.9692 - val_binary_accuracy: 0.7500 - val_loss: 0.6002 - val_precision_2: 0.6667 - val_recall_2: 1.0000\n",
            "Epoch 2/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - binary_accuracy: 0.9627 - loss: 0.1134 - precision_2: 0.9712 - recall_2: 0.9784 - val_binary_accuracy: 1.0000 - val_loss: 0.1135 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n",
            "Epoch 3/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9664 - loss: 0.1042 - precision_2: 0.9766 - recall_2: 0.9778 - val_binary_accuracy: 1.0000 - val_loss: 0.0712 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n",
            "Epoch 4/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - binary_accuracy: 0.9742 - loss: 0.0710 - precision_2: 0.9844 - recall_2: 0.9805 - val_binary_accuracy: 1.0000 - val_loss: 0.0399 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n",
            "Epoch 5/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - binary_accuracy: 0.9828 - loss: 0.0532 - precision_2: 0.9892 - recall_2: 0.9874 - val_binary_accuracy: 1.0000 - val_loss: 0.1202 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n",
            "Epoch 6/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - binary_accuracy: 0.9834 - loss: 0.0468 - precision_2: 0.9901 - recall_2: 0.9874 - val_binary_accuracy: 0.8750 - val_loss: 0.2274 - val_precision_2: 0.8000 - val_recall_2: 1.0000\n",
            "Epoch 7/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - binary_accuracy: 0.9789 - loss: 0.0556 - precision_2: 0.9840 - recall_2: 0.9874 - val_binary_accuracy: 0.9375 - val_loss: 0.1117 - val_precision_2: 0.8889 - val_recall_2: 1.0000\n",
            "Epoch 8/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - binary_accuracy: 0.9877 - loss: 0.0331 - precision_2: 0.9913 - recall_2: 0.9920 - val_binary_accuracy: 1.0000 - val_loss: 0.0384 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n",
            "Epoch 9/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - binary_accuracy: 0.9885 - loss: 0.0307 - precision_2: 0.9932 - recall_2: 0.9913 - val_binary_accuracy: 1.0000 - val_loss: 0.0674 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n",
            "Epoch 10/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.9905 - loss: 0.0255 - precision_2: 0.9935 - recall_2: 0.9936 - val_binary_accuracy: 1.0000 - val_loss: 0.0715 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n",
            "Epoch 11/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - binary_accuracy: 0.9898 - loss: 0.0284 - precision_2: 0.9939 - recall_2: 0.9922 - val_binary_accuracy: 1.0000 - val_loss: 0.0239 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n",
            "Epoch 12/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - binary_accuracy: 0.9927 - loss: 0.0202 - precision_2: 0.9954 - recall_2: 0.9948 - val_binary_accuracy: 1.0000 - val_loss: 0.0222 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n",
            "Epoch 13/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - binary_accuracy: 0.9952 - loss: 0.0113 - precision_2: 0.9981 - recall_2: 0.9954 - val_binary_accuracy: 1.0000 - val_loss: 0.0528 - val_precision_2: 1.0000 - val_recall_2: 1.0000\n",
            "Epoch 14/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - binary_accuracy: 0.9950 - loss: 0.0130 - precision_2: 0.9956 - recall_2: 0.9976 - val_binary_accuracy: 0.9375 - val_loss: 0.1700 - val_precision_2: 0.8889 - val_recall_2: 1.0000\n",
            "Epoch 15/15\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - binary_accuracy: 0.9919 - loss: 0.0241 - precision_2: 0.9932 - recall_2: 0.9958 - val_binary_accuracy: 0.9375 - val_loss: 0.2341 - val_precision_2: 0.8889 - val_recall_2: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f631dfacad0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4b: Evaluate the CNN With Dropout Layers"
      ],
      "metadata": {
        "id": "EajNn1kvia2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below to evaluate your Dropout model. Did your addition of Dropout Layers affect the performance in any substantial way? Try different configurations, layer sizes, etc. and observe the effect on the evaluation metrics."
      ],
      "metadata": {
        "id": "ZLW0BVbVilYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_dropout.evaluate(x_test,y_test)\n",
        "print(f\"Accuracy: {results[1]}\")\n",
        "print(f\"Precision: {results[2]}\")\n",
        "print(f\"Sensitivity: {results[3]}\")"
      ],
      "metadata": {
        "id": "9AWvLZT3h5xJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf4536c9-c928-42c0-c722-238815011c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.5285 - loss: 5.6030 - precision_2: 0.3568 - recall_2: 0.6664\n",
            "Accuracy: 0.7467948794364929\n",
            "Precision: 0.7124541997909546\n",
            "Sensitivity: 0.9974358677864075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you're ready, save your model:\n"
      ],
      "metadata": {
        "id": "e1GEWxT6reaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"drive/MyDrive/\" #(Ex: \"drive/MyDrive/EAS5860/HW4\")\n",
        "\n",
        "model_dropout.save(os.path.join(path, \"EAS5860_HW4_Part_4.keras\"))"
      ],
      "metadata": {
        "id": "bYmlPmhqrn3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5a: Data Augmentation"
      ],
      "metadata": {
        "id": "ljTpX9kqJc3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The quality of any convolutional neural network is limited to the both quality and *quantity* of the available training data. Unfortunately, additional training data is not always available. In such scenarios, we turn to Data Augmentation.\n",
        "\n",
        "Data Augmentation is the process of artifically enhancing the size of our training data set by taking existing images and transforming them (stretching, cropping, mirroring, etc.) to create \"new\" training images. We then train our model on the full set of original images as well as the augmented images in the hopes of improving performance."
      ],
      "metadata": {
        "id": "ej2rNGY_JA_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qe will be using Keras's ImageDataGenerator for Data Augmentation.\n",
        "\n",
        "In the cell below, populate the ImageDataGenerator to achieve the following data augmentations:\n",
        "\n",
        "*   Rotate images by up to 30 degrees\n",
        "*   Zoom in/out by a factor of 0.2\n",
        "*   Shift the image horizontally (width-wise) by a factor of 0.1\n",
        "*   Shift the image vertically (height-wise) by a factor of 0.1\n",
        "*   Introduce a horizontal flip\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zWIqY6pTLIkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        "  )\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "vinFDrf_Flib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the same model from Part 3, just under a new name. We will be training this model again, but with our expanded and augmented data set.\n",
        "\n",
        "As in Part 3/4, add additional layers to the model below. The accuracy goal for this model will be >= 90%."
      ],
      "metadata": {
        "id": "r4bMESml1ZRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_random_seed()\n",
        "\n",
        "aug_model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "aug_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.Precision(), keras.metrics.Recall()])"
      ],
      "metadata": {
        "id": "oMwzOtHfFlk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now train the model. Note the use of `datagen.flow()` in the cell below. This both generates our augmented images (as specified in our `datagen` object) and passes them batch-wise to our model for training.\n",
        "\n",
        "In the cell below, specify the number of epochs and the batch size before training via `aug_model.fit()`"
      ],
      "metadata": {
        "id": "-vyA_VIu3CD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 18\n",
        "batch_size = 32\n",
        "\n",
        "aug_model.fit(datagen.flow(x_train,y_train, batch_size = batch_size) ,epochs = num_epochs , validation_data = datagen.flow(x_val, y_val))"
      ],
      "metadata": {
        "id": "53vsZBTK2p2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3fe9980-1f08-4e37-8e7d-452ec1dfbe51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 136ms/step - binary_accuracy: 0.7637 - loss: 0.5754 - precision_5: 0.7704 - recall_5: 0.9787 - val_binary_accuracy: 0.8125 - val_loss: 0.6526 - val_precision_5: 0.7273 - val_recall_5: 1.0000\n",
            "Epoch 2/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 117ms/step - binary_accuracy: 0.8649 - loss: 0.3240 - precision_5: 0.8930 - recall_5: 0.9295 - val_binary_accuracy: 0.7500 - val_loss: 0.7617 - val_precision_5: 0.6667 - val_recall_5: 1.0000\n",
            "Epoch 3/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 109ms/step - binary_accuracy: 0.9009 - loss: 0.2488 - precision_5: 0.9330 - recall_5: 0.9342 - val_binary_accuracy: 0.6250 - val_loss: 1.5229 - val_precision_5: 0.5714 - val_recall_5: 1.0000\n",
            "Epoch 4/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 122ms/step - binary_accuracy: 0.8994 - loss: 0.2328 - precision_5: 0.9321 - recall_5: 0.9326 - val_binary_accuracy: 0.6250 - val_loss: 1.2955 - val_precision_5: 0.5714 - val_recall_5: 1.0000\n",
            "Epoch 5/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 109ms/step - binary_accuracy: 0.9199 - loss: 0.1980 - precision_5: 0.9430 - recall_5: 0.9496 - val_binary_accuracy: 0.7500 - val_loss: 0.5581 - val_precision_5: 0.6667 - val_recall_5: 1.0000\n",
            "Epoch 6/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 112ms/step - binary_accuracy: 0.9223 - loss: 0.2051 - precision_5: 0.9455 - recall_5: 0.9495 - val_binary_accuracy: 0.6250 - val_loss: 1.6075 - val_precision_5: 0.5714 - val_recall_5: 1.0000\n",
            "Epoch 7/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 117ms/step - binary_accuracy: 0.9178 - loss: 0.1971 - precision_5: 0.9402 - recall_5: 0.9490 - val_binary_accuracy: 0.6875 - val_loss: 1.1851 - val_precision_5: 0.6154 - val_recall_5: 1.0000\n",
            "Epoch 8/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 114ms/step - binary_accuracy: 0.9323 - loss: 0.1697 - precision_5: 0.9550 - recall_5: 0.9545 - val_binary_accuracy: 0.6875 - val_loss: 1.3844 - val_precision_5: 0.6154 - val_recall_5: 1.0000\n",
            "Epoch 9/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 113ms/step - binary_accuracy: 0.9404 - loss: 0.1648 - precision_5: 0.9631 - recall_5: 0.9566 - val_binary_accuracy: 0.6250 - val_loss: 1.1973 - val_precision_5: 0.5833 - val_recall_5: 0.8750\n",
            "Epoch 10/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - binary_accuracy: 0.9432 - loss: 0.1637 - precision_5: 0.9621 - recall_5: 0.9617 - val_binary_accuracy: 0.5625 - val_loss: 1.4464 - val_precision_5: 0.5333 - val_recall_5: 1.0000\n",
            "Epoch 11/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 111ms/step - binary_accuracy: 0.9455 - loss: 0.1467 - precision_5: 0.9652 - recall_5: 0.9627 - val_binary_accuracy: 0.8125 - val_loss: 0.9807 - val_precision_5: 0.7273 - val_recall_5: 1.0000\n",
            "Epoch 12/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 118ms/step - binary_accuracy: 0.9264 - loss: 0.1783 - precision_5: 0.9504 - recall_5: 0.9510 - val_binary_accuracy: 0.7500 - val_loss: 1.0399 - val_precision_5: 0.6667 - val_recall_5: 1.0000\n",
            "Epoch 13/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 113ms/step - binary_accuracy: 0.9366 - loss: 0.1663 - precision_5: 0.9567 - recall_5: 0.9562 - val_binary_accuracy: 0.6875 - val_loss: 0.8145 - val_precision_5: 0.6364 - val_recall_5: 0.8750\n",
            "Epoch 14/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 116ms/step - binary_accuracy: 0.9454 - loss: 0.1431 - precision_5: 0.9672 - recall_5: 0.9599 - val_binary_accuracy: 0.5625 - val_loss: 1.8202 - val_precision_5: 0.5333 - val_recall_5: 1.0000\n",
            "Epoch 15/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 115ms/step - binary_accuracy: 0.9364 - loss: 0.1656 - precision_5: 0.9564 - recall_5: 0.9584 - val_binary_accuracy: 0.7500 - val_loss: 1.1912 - val_precision_5: 0.6667 - val_recall_5: 1.0000\n",
            "Epoch 16/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 111ms/step - binary_accuracy: 0.9522 - loss: 0.1398 - precision_5: 0.9682 - recall_5: 0.9670 - val_binary_accuracy: 0.6875 - val_loss: 0.7744 - val_precision_5: 0.6154 - val_recall_5: 1.0000\n",
            "Epoch 17/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 115ms/step - binary_accuracy: 0.9453 - loss: 0.1475 - precision_5: 0.9644 - recall_5: 0.9614 - val_binary_accuracy: 0.7500 - val_loss: 0.8972 - val_precision_5: 0.6667 - val_recall_5: 1.0000\n",
            "Epoch 18/18\n",
            "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 116ms/step - binary_accuracy: 0.9516 - loss: 0.1337 - precision_5: 0.9686 - recall_5: 0.9666 - val_binary_accuracy: 0.6875 - val_loss: 1.0342 - val_precision_5: 0.6154 - val_recall_5: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f631de4ff50>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5b: Evaluate the CNN Trained on Augmented Data"
      ],
      "metadata": {
        "id": "dXw5ZzHy4DYh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's time to once again generate predictions and evaluate our model. To do so, run the cell below. Thanks to data augmentation, you should be able to achieve accuracy scores >= 90%. If not, try adjusting the placement/composition of your Conv2D, MaxPooling, or DropOut layers. Also consider adjusting your epochs/batch size."
      ],
      "metadata": {
        "id": "b1f6LjKK4WVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = aug_model.evaluate(x_test,y_test)\n",
        "print(f\"Accuracy: {results[1]}\")\n",
        "print(f\"Precision: {results[2]}\")\n",
        "print(f\"Sensitivity: {results[3]}\")"
      ],
      "metadata": {
        "id": "yzDpmg3c4qAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6122c89-98c9-47d9-8dc6-df7e23aea87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8867 - loss: 0.4520 - precision_5: 0.5270 - recall_5: 0.6437\n",
            "Accuracy: 0.9198718070983887\n",
            "Precision: 0.9086538553237915\n",
            "Sensitivity: 0.9692307710647583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you're pleased with your results, save your model as before:\n"
      ],
      "metadata": {
        "id": "sct-F_ai4953"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"drive/MyDrive/\" #(Ex: \"drive/MyDrive/EAS5860/HW4\")\n",
        "\n",
        "aug_model.save(os.path.join(path, \"EAS5860_HW4_Part_5.keras\"))"
      ],
      "metadata": {
        "id": "z2sNp5ph5HcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Good Work!\n",
        "\n",
        "Feel free to return here to try out new experiments in the future!"
      ],
      "metadata": {
        "id": "zdR3euGwsEdn"
      }
    }
  ]
}